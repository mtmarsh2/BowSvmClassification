from __future__ import division
import cv2
import numpy as np
import glob
import os
from sklearn.cluster import KMeans, MiniBatchKMeans
import scipy.cluster.vq as vq
import pdb
import cPickle as pickle
import numpy
from sklearn import svm
import random
import os.path
from scipy import spatial

sift = cv2.SIFT()
all_image_histograms = {}
image_to_descriptors = {}
non_logo_image_descriptors = {}
folder_name = "/Users/User1/Downloads/FlickrLogos-v2/classes/jpg/starbucks/"
other_folder_name = "/Users/User1/Downloads/FlickrLogos-v2/classes/jpg/no-logo/"
list_of_logo_image_names = glob.glob(os.path.join(folder_name, "*.jpg"))[:5]
list_of_non_logo_image_names = glob.glob(os.path.join(other_folder_name, "*.jpg"))[:50]
assert(len(list_of_logo_image_names) != 0)
assert(len(list_of_non_logo_image_names) != 0)

#1. Read in all images
#2. Generate vocabulary list
#3. Generate histogram bow representation for all images
#4. Run nearest neighbor on target image to find top k close images
#5. See which parameter k is best for classification 

def create_histogram(labels):
     hist, edges = np.histogram(labels, bins=range(num_clusters), normed=True)
     return hist

def combine_with_mask(image_path):
    image_name = os.path.basename(image_path)
    path_to_mask = "/Users/User1/Downloads/FlickrLogos-v2/classes/masks/starbucks/%s.mask.0.png" % image_name
    return cv2.bitwise_and(cv2.imread(image_name), cv2.imread(path_to_mask))

def get_sift_descriptors(image_name):
     img = cv2.imread(image_name)
     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
     [kp, desc] =  sift.detectAndCompute(gray, None)
     #return only subset
     #num_elems = min(500, len(desc))
     #return random.sample(desc, num_elems)
     return kp, desc
def build_dataset(list_of_image_names):
     image_to_descriptors = {}
     for index,image_name in enumerate(list_of_image_names):
          image_to_descriptors[image_name] = get_sift_descriptors(image_name)
     return image_to_descriptors

def create_histogram(labels):
     hist, edges = np.histogram(labels, bins=num_clusters)
     return hist

num_clusters = 10000

# ===== Produce logo + mask images
for image_name in list_of_logo_image_names:
    logo_and_mask_image = combine_with_mask(image_name)
    assert(len(logo_and_mask_image) != 0)
    cv2.imwrite("/Users/User1/Downloads/FlickrLogos-v2/classes/combined/%s" % image_name, logo_and_mask_image)

# ===== Read in logo + mask images and compute sift descriptors
image_to_descriptors = build_dataset(list_of_logo_image_names)
list_of_sift_descriptors_logos = np.vstack(image_to_descriptors.values())

# ===== Read in non logo images and compute sift descriptors on those also
non_logo_image_descriptors = build_dataset(list_of_non_logo_image_names)
list_of_sift_descriptors_nonlogos = np.vstack(non_logo_image_descriptors.values())

all_descriptors = np.vstack( (list_of_sift_descriptors_logos, list_of_sift_descriptors_nonlogos))

# ===== Build vocab list using kmeans
kmeans = MiniBatchKMeans(n_clusters = num_clusters)
kmeans.fit(all_descriptors)

# ===== Compute histogram for all logo images
for index,image_name in enumerate(list_of_logo_image_names):
     if index % 1000 ==0: print index
     #image_to_descriptors[image_name] = get_sift_descriptors(image_name)
     labels = kmeans.predict(image_to_descriptors[image_name])
     all_image_histograms[image_name] = create_histogram(labels)

# ===== Compute histogram for all non logo images
for index,image_name in enumerate(list_of_non_logo_image_names):
     if index % 1000 ==0: print index
     #image_to_descriptors[image_name] = get_sift_descriptors(image_name)
     labels = kmeans.predict(non_logo_image_descriptors[image_name])
     all_image_histograms[image_name] = create_histogram(labels)

mytree = spatial.KDTree(all_image_histograms.values())

# ===== Take new starbucks logo image and compute binary 'and' with histogram of all other images
for i in range(5, len())
new_image = glob.glob(os.path.join(folder_name, "*.jpg"))[5]

logo_and_mask_image = combine_with_mask(new_image)
assert(len(logo_and_mask_image) != 0)
cv2.imwrite("/Users/User1/Downloads/FlickrLogos-v2/classes/combined/%s" % os.path.basename(new_image), logo_and_mask_image)
target_image_descriptor = build_dataset([new_image])
labels = kmeans.predict(target_image_descriptor[new_image])
target_histogram = create_histogram(labels)
assert( len(target_histogram) == num_clusters)
# ===== Filter out wrong images with ransac
[a,b] = mytree.query(target_histogram)
# ===== Take category of top k images
